{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c5c7bf",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "In this notebook, we will explore Large Language Models (LLMs) using use the OpenAI API. An **API (Application Programming Interface)** allows different software applications to communicate with one another. By using the OpenAI API, we can connect to OpenAI's language models, such as GPT-4, to generate human-like text and perform a variety of tasks, such as answering questions, summarizing, translating, and more.\n",
    "\n",
    "## API Key Setup\n",
    "\n",
    "To begin using the OpenAI API, we need to set up an API key. This key connects the code to your OpenAI account and manages the billing. OpenAI charges based on the number of tokens (words or chunks of words) processed. Different models have different pricing structures, based on their size and capabilities.\n",
    "\n",
    "- **GPT-4o** is the latest and most advanced model, designed for a wide range of general-purpose tasks.\n",
    "\n",
    "To set the API key, we need to configure it as an environment variable, which can vary depending on the type of machine you're using.\n",
    "\n",
    "For detailed documentation and additional usage instructions, please refer to the [OpenAI API Reference](https://platform.openai.com/docs/api-reference).\n",
    "\n",
    "### Windows Users\n",
    "\n",
    "If you're using a Windows machine, uncomment and run the following code block to set your environment variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !setx OPENAI_API_KEY \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb414b4",
   "metadata": {},
   "source": [
    "### Mac/Linux Users\n",
    "\n",
    "Uncomment & run the below chunk if utilizing a *nix machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export OPENAI_API_KEY \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e9842",
   "metadata": {},
   "source": [
    "## Installing the OpenAI Python Package\n",
    "\n",
    "Before interacting with the OpenAI API, we need to ensure that the OpenAI Python package is installed. This package provides a simple interface to the OpenAI API, allowing us to make requests and receive responses.\n",
    "\n",
    "To install the package, run the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52428d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305319f",
   "metadata": {},
   "source": [
    "### What is a large langauge model (LLM)?\n",
    "\n",
    "* AI system designed to process and generate human-like language at scale.\n",
    "* Utilizes deep learning \n",
    "* Trained on massive amounts of text data to learn patterns and relationships in language.\n",
    "* \"Large\" because they often contain billions of parameters\n",
    "    * Think of parameters as being mathematically similar to regression \n",
    "        * $y=x_1Parameter_1 + x_2Parameter_2 + \\cdots$\n",
    "    * Captures a wide range of linguistic features and nuances\n",
    "        * GPT-1     117 million parameters\n",
    "        * GPT-2     1.5 billion parameters\n",
    "        * GPT-3     175 billion parameters\n",
    "        * GPT-4     ? maybe trillion+\n",
    "* Reasonably complex architecture\n",
    "* At is essence, just a bunch of (clever) matrix algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa4cf",
   "metadata": {},
   "source": [
    "How does an LLM operate?\n",
    "\n",
    "We'll focus on three parameters:\n",
    "* Max tokens\n",
    "    * The maximum number of tokens to generate in the completion\n",
    "* Temperature\n",
    "    * Low = Less creative\n",
    "    * High = more creative\n",
    "* Logprobs\n",
    "    * Include log probabilities of other most likely tokens\n",
    "\n",
    "Let's consider a GPT-3 model\n",
    "* Low temperature (same response every time we run it)\n",
    "* Limit the response to 10 tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8cb82",
   "metadata": {},
   "source": [
    "## Making an API Request to OpenAI\n",
    "\n",
    "After installing the OpenAI Python package, we can start making API requests. In the following example, we use the **OpenAI client** to generate a text completion with a specified model, prompt, and additional parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a383148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"davinci-002\",\n",
    "  prompt=\"The Miller College of Business at Ball State is the best in the world because\",\n",
    "  max_tokens=10,\n",
    "  temperature=0.9,\n",
    "    logprobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs = response.choices[0].logprobs\n",
    "\n",
    "# Creating a DataFrame from the extracted components\n",
    "df = pd.DataFrame({\n",
    "    'text_offset': logprobs.text_offset,\n",
    "    'token_logprobs': logprobs.token_logprobs,\n",
    "    'tokens': logprobs.tokens,\n",
    "    'top_logprobs': logprobs.top_logprobs\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c4c22",
   "metadata": {},
   "source": [
    "Other \"useful\" parameters:\n",
    "* Logit Bias\n",
    "    * Intoduce bias to tokens\n",
    "    * i.e. Ban or exclusively select words, phrases, topics, etc.\n",
    "    * Continuous parameter\n",
    "* Frequency Penalty\n",
    "    * Encourage (or discourage) generation of unique tokens in a response\n",
    "    * Can help prevent repeated responses\n",
    "* Presence Penalty\n",
    "    * Encourage (or discourage) model to make novel predictions\n",
    "    * Doesn't depend on the frequency of past predictions\n",
    "\n",
    "If you want to know more...\n",
    "\n",
    "[Amazing, comprehensive explanation by Stephen Wolfram](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fa884",
   "metadata": {},
   "source": [
    "## Utilizing GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain 2024 tax law changes relevant for individual returns in the style of a star wars title crawl.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa121be",
   "metadata": {},
   "source": [
    "## A more advanced prompting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Doug and Pam Prospect are retired and ages 79 and 78 respectively. Doug was a former executive and Pam historically stayed at home with their children.  Today, they spend most of their time traveling to see their three adult children and eight grandchildren.  When not traveling, they are very engaged and active with their local church.  \n",
    "Doug and Pam have approximately $5,000,000 in investable assets at a large investment advisory firm and a home valued at $1,000,000 with no debt. Their assets are invested exclusively in public markets with approximately 70% in equities and 30% in fixed income securities; all of which are either mutual funds or exchange traded funds (ETFs).   A further breakdown of the investable assets indicates that $1,000,0000 is held in a Traditional IRA and the balance in non-qualified accounts, which have a net unrealized long-term capital gain of approximately $250,000.\n",
    "Doug and Pam are leery of any investment that is not liquid and would prefer securities that can be converted into cash quickly due to a “bad experience” in a private REIT.  They consistently talk about cash flow and worry about how to fund their lifestyle expenses as a result of a volatile 2022 market.  They have estimated their annual expenses to be approximately $250,000 (after-tax).  \n",
    "During the prospecting discussions, Doug repeatedly shared his fear about the current administration’s focus on potential tax increases and the potential of a recession. They were concerned that these potential events could jeopardize their future and the wealth that they’ve worked so hard to accumulate.\n",
    "Doug and Pam are losing trust in their current financial advisor, although they have glowing reviews about their “Dividend Stock Strategy” and the support team at the brokerage firm.  They felt like their advisor was not addressing their questions or concerns and often received the “canned” company response.   After CLA reviewed the performance of this strategy, the strategy has underperformed compared to corresponding benchmarks.  \n",
    "The prospect has their taxes prepared by a well-known regional CPA firm and is expecting a tax liability of $300,000 due to a large capital gain event in the current year. Doug and Pam shared this is a one-time event and is not expected to repeat in the future.  Although the prospect believes in paying their fair share of taxes, they would like to understand if they can minimize their tax liabilities. Historically, Doug and Pam are made aware of their tax liabilities when they pick up their tax return in April each year. \n",
    "The prospect is charitably inclined.  In the past year, Doug and Pam donated $20,000 in cash donations writing multiple checks to their church and other 501(c)(3) organizations. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "You are a tax accountant and wealth advisor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = \"\"\"\n",
    "Adapt your response to this scenario. \n",
    "Compare and contrast different approaches. \n",
    "Provide specific strategies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ffb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Doug and Pam would like to reduce their income tax liability in the current year given the large capital gain, how can they do so?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb993297",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": context + comments + prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b652f",
   "metadata": {},
   "source": [
    "# Passing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb77809",
   "metadata": {},
   "source": [
    "## Loading and Displaying Financial Data\n",
    "\n",
    "In this section, we load a CSV file containing financial data into a **Pandas DataFrame** for analysis. The **Pandas** library is a powerful tool in Python for data manipulation and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4572029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"financial_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b24e3",
   "metadata": {},
   "source": [
    "Add data to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = f\"\"\"\n",
    "Analyze the following quarterly financial data for FY2023 and provide actionable recommendations to improve profitability. \n",
    "\n",
    "Highlight key trends, issues, and areas for improvement.\n",
    "\n",
    "{df}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b1b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "completion_3 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_data\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec1f6a",
   "metadata": {},
   "source": [
    "# Use Assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851167ea",
   "metadata": {},
   "source": [
    "## Image Analysis Using an Assistant\n",
    "\n",
    "In this section of code, we are utilizing a client assistant to perform image analysis specifically for OSHA (Occupational Safety and Health Administration) compliance checks. Below is an overview of the steps involved:\n",
    "\n",
    "1. **Uploading the Image**  \n",
    "   The image (`osha.png`) is uploaded to the system with a purpose related to vision-based tasks. This image will later be analyzed for potential OSHA violations.\n",
    "\n",
    "2. **Creating an Assistant**  \n",
    "   We create an assistant named \"OSHA Inspector\" using the GPT-4 model. The assistant is designed to analyze the uploaded image and identify OSHA violations. It is equipped with a code interpreter tool to help it process the image.\n",
    "\n",
    "3. **Initiating the Analysis Request**  \n",
    "   A thread is created where the assistant is instructed to identify all OSHA violations in the uploaded image, cite the relevant laws, and suggest better practices.\n",
    "\n",
    "4. **Running the Analysis**  \n",
    "   The analysis is triggered, and we poll the system for results. If the process is completed successfully, it outputs \"Done!\"; otherwise, it checks the current status.\n",
    "\n",
    "5. **Retrieving the Results**  \n",
    "   Once the analysis is complete, we retrieve the results from the assistant and print the text-based findings to the console.\n",
    "\n",
    "This workflow automates the process of identifying OSHA violations from an image, providing detailed feedback and suggestions based on OSHA standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3870a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_image = client.files.create(\n",
    "  file=open(\"osha.png\", \"rb\"),\n",
    "  purpose='vision'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_assistant = client.beta.assistants.create(\n",
    "  name=\"OSHA Inspector\",\n",
    "  description=\"You are an OSHA Inspector. Analyze the attached images and identify all OSHA violations.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [osha_image.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Identify all OSHA violations, cite the law, & describe better practices for each.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_file\",\n",
    "          \"image_file\": {\"file_id\": osha_image.id}\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=osha_thread.id,\n",
    "  assistant_id=osha_assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b97ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if osha_run.status == 'completed': \n",
    "  print(\"Done!\")\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_messages = client.beta.threads.messages.list(\n",
    "    thread_id=osha_thread.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# osha_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbea00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in osha_messages.data:\n",
    "    for content_block in message.content:\n",
    "        if content_block.type == 'text':\n",
    "            print(content_block.text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373924b3",
   "metadata": {},
   "source": [
    "## Data Analysis Using an Assistant\n",
    "\n",
    "In this section of code, we are using a client assistant to perform data analysis and create visualizations from a CSV file. Here's a summary of the steps involved:\n",
    "\n",
    "1. **Uploading the Data**  \n",
    "   A CSV file containing data is uploaded to the system. This file will be used for analysis and visualization.\n",
    "\n",
    "2. **Creating an Assistant**  \n",
    "   We create an assistant named \"Data Visualizer\" using the GPT-4 model. This assistant is designed to analyze data from CSV files, identify trends, and generate relevant visualizations. Additionally, the assistant provides a brief summary of the trends observed.\n",
    "\n",
    "3. **Initiating the Data Analysis Request**  \n",
    "   A thread is created where the assistant is instructed to generate three data visualizations based on the trends found in the CSV file. The file is attached to this request, and the code interpreter tool is utilized to analyze it.\n",
    "\n",
    "4. **Running the Analysis**  \n",
    "   The assistant's analysis is triggered, and we poll the system for the results. If the analysis is successful, it confirms completion; otherwise, it checks the status.\n",
    "\n",
    "5. **Retrieving the Results**  \n",
    "   Once the process is complete, we retrieve the messages generated by the assistant. The assistant's output includes both the data visualizations and a summary of the trends identified from the CSV file.\n",
    "\n",
    "This workflow automates the process of analyzing data from a CSV file, generating visualizations, and summarizing key trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"HR_comma_sep.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Data visualizer\",\n",
    "  description=\"You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Create 3 data visualizations based on the trends in this file.\",\n",
    "      \"attachments\": [\n",
    "        {\n",
    "          \"file_id\": file.id,\n",
    "          \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == 'completed': \n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(\"Done!\")\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ee4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to extract all file IDs from SyncCursorPage[Message] object\n",
    "def extract_file_ids(message_object):\n",
    "    file_ids = []\n",
    "    \n",
    "    # Assuming the object has a 'data' attribute that contains the messages\n",
    "    messages = message_object.data  # Access the 'data' attribute\n",
    "    \n",
    "    # Loop through all messages\n",
    "    for message in messages:\n",
    "        # Check if the message contains 'content'\n",
    "        if hasattr(message, 'content'):\n",
    "            # Loop through each content block\n",
    "            for content_block in message.content:\n",
    "                # Check if the content block is of type 'image_file'\n",
    "                if content_block.type == 'image_file' and hasattr(content_block, 'image_file'):\n",
    "                    # Extract the file_id and add it to the list\n",
    "                    file_ids.append(content_block.image_file.file_id)\n",
    "    \n",
    "    return file_ids\n",
    "\n",
    "# Now extract file IDs from the 'messages' object\n",
    "file_ids = extract_file_ids(messages)\n",
    "\n",
    "# Output the file IDs\n",
    "print(\"Extracted file IDs:\", file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5383877",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_id in file_ids:\n",
    "    content = client.files.content(file_id)\n",
    "    content_bytes = content.read()\n",
    "    with open(f\"{file_id}.png\", \"wb\") as file:\n",
    "        file.write(content_bytes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming the files are saved as .png in the current directory\n",
    "for file_id in file_ids:\n",
    "    content = client.files.content(file_id)\n",
    "    content_bytes = content.read()\n",
    "    \n",
    "    # Save the file as before\n",
    "    file_path = f\"{file_id}.png\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(content_bytes)\n",
    "    \n",
    "    # Display the saved image\n",
    "    img = Image.open(file_path)\n",
    "    display.display(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
